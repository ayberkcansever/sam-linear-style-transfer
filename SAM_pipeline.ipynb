{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22cae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "import scipy.ndimage\n",
    "import torchvision\n",
    "\n",
    "interactive_fig = None\n",
    "interactive_fig_styles = None\n",
    "\n",
    "def plot_images(images, titles, figure_size):\n",
    "    %matplotlib inline\n",
    "    if interactive_fig is not None:\n",
    "        plt.close(interactive_fig)\n",
    "    if interactive_fig_styles is not None:\n",
    "        plt.close(interactive_fig_styles)\n",
    "    plt.figure(figsize=(figure_size, figure_size))\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        title = titles[i]\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "\n",
    "def resize_to(image, target):\n",
    "    target_height, target_width = target.shape[:2]\n",
    "    image = cv2.resize(image, (target_width, target_height), interpolation=cv2.INTER_LINEAR)\n",
    "    return image\n",
    "\n",
    "def regenerate(org_image, masked_image, mask):\n",
    "    if isinstance(mask, torch.Tensor):\n",
    "        mask = mask.squeeze().cpu().numpy().astype(np.uint8) * 255\n",
    "        mask = cv2.resize(mask, (org_image.shape[1], org_image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        mask = mask.astype(np.uint8)\n",
    "        \n",
    "    inverse_mask = cv2.bitwise_not(mask)\n",
    "    masked_original = cv2.bitwise_and(org_image, org_image, mask=inverse_mask)\n",
    "    styled_masked = cv2.bitwise_and(masked_image, masked_image, mask=mask)\n",
    "    return cv2.add(masked_original, styled_masked) \n",
    "\n",
    "def plot_tensor_image(tensor):\n",
    "    if tensor.is_cuda:\n",
    "        tensor = tensor.cpu()\n",
    "    \n",
    "    tensor = tensor.detach()\n",
    "    \n",
    "    if tensor.dim() == 4 and tensor.size(0) == 1 and tensor.size(1) == 1:\n",
    "        tensor = tensor.squeeze(0).squeeze(0)  \n",
    "        plt.imshow(tensor.numpy(), cmap='gray')\n",
    "    elif tensor.dim() == 3 and tensor.size(0) == 1:\n",
    "        tensor = tensor.squeeze(0)\n",
    "        plt.imshow(tensor.numpy(), cmap='gray')\n",
    "    elif tensor.dim() == 3 and tensor.size(0) in [1, 3]:\n",
    "        tensor = tensor.permute(1, 2, 0).numpy()\n",
    "        tensor = (tensor - tensor.min()) / (tensor.max() - tensor.min()) \n",
    "        plt.imshow(tensor)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected tensor shape: {tensor.shape}\")\n",
    "\n",
    "    plt.axis('off')  # Hide axis\n",
    "    plt.show()\n",
    "\n",
    "def extract_borders(mask, border_thickness, border_type='inner'):\n",
    "    binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    kernel = np.ones((border_thickness, border_thickness), np.uint8)\n",
    "    \n",
    "    if border_type == 'inner':\n",
    "        # Erode the mask for inner borders\n",
    "        eroded_mask = cv2.erode(binary_mask, kernel, iterations=1)\n",
    "        border_mask = binary_mask - eroded_mask\n",
    "    elif border_type == 'outer':\n",
    "        # Dilate the mask for outer borders\n",
    "        dilated_mask = cv2.dilate(binary_mask, kernel, iterations=1)\n",
    "        border_mask = dilated_mask - binary_mask\n",
    "    elif border_type == 'both':\n",
    "        # Extract both inner and outer borders\n",
    "        eroded_mask = cv2.erode(binary_mask, kernel, iterations=1)\n",
    "        inner_border_mask = binary_mask - eroded_mask\n",
    "        \n",
    "        dilated_mask = cv2.dilate(binary_mask, kernel, iterations=1)\n",
    "        outer_border_mask = dilated_mask - binary_mask\n",
    "        \n",
    "        # Combine inner and outer borders\n",
    "        border_mask = cv2.bitwise_or(inner_border_mask, outer_border_mask)\n",
    "    else:\n",
    "        raise ValueError(\"border_type must be either 'inner', 'outer', or 'both'\")\n",
    "    \n",
    "    return border_mask\n",
    "\n",
    "def apply_border_mask(image, mask, border_thickness, border_type='inner'):\n",
    "    border_mask = extract_borders(mask, border_thickness, border_type=border_type)\n",
    "    border_mask_3channel = cv2.merge([border_mask]*3)\n",
    "    border_extracted_image = cv2.bitwise_and(image, border_mask_3channel)\n",
    "    return border_extracted_image\n",
    "    \n",
    "def penetrate_mask(mask, radius, shrink=0):\n",
    "    import scipy.ndimage \n",
    "    import numpy as np\n",
    "\n",
    "    mask = mask.float()\n",
    "    mask_np = mask.squeeze(0).cpu().numpy() \n",
    "\n",
    "    if shrink > 0:\n",
    "        eroded_mask_np = scipy.ndimage.binary_erosion(mask_np, iterations=shrink).astype(mask_np.dtype)\n",
    "    else:\n",
    "        eroded_mask_np = mask_np\n",
    "\n",
    "    distance_map = scipy.ndimage.distance_transform_edt(eroded_mask_np == 0)\n",
    "    penetration_mask_np = np.clip((radius - distance_map) / radius, 0, 1)\n",
    "    penetration_mask = torch.tensor(penetration_mask_np, device=mask.device, dtype=mask.dtype).unsqueeze(0)\n",
    "\n",
    "    return penetration_mask \n",
    "\n",
    "def get_mask_borders(mask, inside_pixels, outside_pixels):\n",
    "    mask = (mask > 0).astype(np.uint8)\n",
    "    inside_eroded = cv2.erode(mask, np.ones((inside_pixels, inside_pixels), np.uint8)) if inside_pixels > 0 else mask\n",
    "    outside_dilated = cv2.dilate(mask, np.ones((outside_pixels, outside_pixels), np.uint8)) if outside_pixels > 0 else mask\n",
    "    border_mask = outside_dilated - inside_eroded\n",
    "    return border_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aec9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "from libs import Matrix, models, Matrix_masked, models_masked\n",
    "from libs.Matrix import MulLayer\n",
    "from libs.models import encoder4, decoder4\n",
    "from libs.Matrix_masked import MulLayer as MulLayer_m\n",
    "from libs.models_masked import encoder4 as encoder_m, decoder4 as decoder_m\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from skimage.feature import local_binary_pattern\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import chisquare\n",
    "from skimage.color import rgb2lab\n",
    "from skimage.color import deltaE_ciede2000\n",
    "\n",
    "def generateSmallMask(x, mask):\n",
    "    b, c, h, w = x.shape\n",
    "    small_mask = mask\n",
    "    small_mask = torch.nn.functional.interpolate(small_mask, size=(h, w), mode='bilinear', align_corners=False)\n",
    "    return small_mask.squeeze(0)\n",
    "\n",
    "def gramMatrix(features):\n",
    "    # Assumes flattened input\n",
    "    b, c, l = features.size()\n",
    "    G = torch.bmm(features,features.transpose(1,2)) # f: bxcx(hxw), f.transpose: bx(hxw)xc -> bxcxc\n",
    "    return G.div_(c*l)\n",
    "\n",
    "def styleLoss(features,target,mask):\n",
    "    ib,ic,ih,iw = features.size()\n",
    "    iF = features.view(ib,ic,-1)\n",
    "    imask = mask.view(ib,1,-1)\n",
    "    iF = iF.masked_select(imask.expand_as(iF) > 0)\n",
    "    iF = iF.view(ib, ic, -1)\n",
    "    iMean = torch.mean(iF,dim=2)\n",
    "    iCov = gramMatrix(iF)\n",
    "\n",
    "    tb,tc,th,tw = target.size()\n",
    "    tF = target.view(tb,tc,-1)\n",
    "    tMean = torch.mean(tF,dim=2)\n",
    "    tCov = gramMatrix(tF)\n",
    "\n",
    "    loss = torch.nn.MSELoss(reduction=\"sum\")(iMean,tMean) + torch.nn.MSELoss(reduction=\"sum\")(iCov,tCov)\n",
    "    return loss/tb\n",
    "\n",
    "def image_to_tensor(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_tensor = F.to_tensor(image)\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    return image_tensor\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor.squeeze(0)\n",
    "    image = tensor.detach().cpu().numpy()\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    image = (image * 255).clip(0, 255).astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "def calculate_gradient_magnitude_around_border(image, mask):\n",
    "    if len(mask.shape) == 3:\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask = (mask > 0).astype(np.uint8)\n",
    "    \n",
    "    grad_magnitudes = []\n",
    "    for c in range(3): \n",
    "        grad_x = cv2.Sobel(image[:, :, c], cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(image[:, :, c], cv2.CV_64F, 0, 1, ksize=3)\n",
    "        grad_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "        grad_magnitudes.append(grad_magnitude)\n",
    "    \n",
    "    # Combine gradient magnitudes across channels1\n",
    "    gradient_magnitude = np.mean(grad_magnitudes, axis=0)\n",
    "    \n",
    "    # Apply the mask to isolate the border\n",
    "    border_gradient_magnitude = gradient_magnitude * mask\n",
    "    border_pixels = border_gradient_magnitude[mask > 0]\n",
    "\n",
    "    mean_gradient = np.mean(border_pixels)\n",
    "    std_gradient = np.std(border_pixels)\n",
    "    median_gradient = np.median(border_pixels)\n",
    "    return mean_gradient, std_gradient, median_gradient\n",
    "\n",
    "def calculate_texture_continuity(blended_image, inner_border_mask, outer_border_mask, radius=1, n_points=8):\n",
    "    inner_border_mask = (inner_border_mask > 0).astype(np.uint8)\n",
    "    outer_border_mask = (outer_border_mask > 0).astype(np.uint8)\n",
    "    \n",
    "    lbp_histograms_inner = []\n",
    "    lbp_histograms_outer = []\n",
    "    \n",
    "    # Process each color channel\n",
    "    for c in range(3): \n",
    "        channel_image = blended_image[:, :, c]\n",
    "        lbp_image = local_binary_pattern(channel_image, n_points, radius, method='uniform')\n",
    "        \n",
    "        # Extract LBP values within the inner and outer masks\n",
    "        inner_area = lbp_image[inner_border_mask > 0]\n",
    "        outer_area = lbp_image[outer_border_mask > 0]\n",
    "        \n",
    "        # Calculate histograms for each channel\n",
    "        bins = np.arange(0, n_points + 3)\n",
    "        inner_hist, _ = np.histogram(inner_area, bins=bins)\n",
    "        outer_hist, _ = np.histogram(outer_area, bins=bins)\n",
    "        \n",
    "        lbp_histograms_inner.append(inner_hist)\n",
    "        lbp_histograms_outer.append(outer_hist)\n",
    "    \n",
    "    # Combine histograms from all channels\n",
    "    inner_hist_total = np.concatenate(lbp_histograms_inner)\n",
    "    outer_hist_total = np.concatenate(lbp_histograms_outer)\n",
    "    \n",
    "    # Normalize histograms\n",
    "    eps = 1e-10\n",
    "    inner_hist_total = inner_hist_total.astype(np.float32)\n",
    "    outer_hist_total = outer_hist_total.astype(np.float32)\n",
    "    inner_hist_total /= (inner_hist_total.sum() + eps)\n",
    "    outer_hist_total /= (outer_hist_total.sum() + eps)\n",
    "    \n",
    "    # Compute Chi-square distance\n",
    "    chi2_distance = 0.5 * np.sum(((inner_hist_total - outer_hist_total) ** 2) / (inner_hist_total + outer_hist_total + eps))\n",
    "    \n",
    "    return chi2_distance\n",
    "\n",
    "def calculate_color_continuity_along_border(image, border_mask):\n",
    "    \n",
    "    border_mask = (border_mask > 0).astype(np.uint8)\n",
    "\n",
    "    border_coords = np.column_stack(np.where(border_mask == 1))\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    color_differences = []\n",
    "\n",
    "    # Define 8-connected neighborhood offsets\n",
    "    offsets = [(-1, -1), (-1, 0), (-1, 1),\n",
    "               (0, -1),          (0, 1),\n",
    "               (1, -1),  (1, 0), (1, 1)]\n",
    "\n",
    "    border_pixel_set = set(map(tuple, border_coords))\n",
    "\n",
    "    for y, x in border_coords:\n",
    "        pixel_color = image_lab[y, x, :]\n",
    "\n",
    "        for dy, dx in offsets:\n",
    "            ny, nx = y + dy, x + dx\n",
    "\n",
    "            # Check if neighbor is within image bounds\n",
    "            if 0 <= ny < border_mask.shape[0] and 0 <= nx < border_mask.shape[1]:\n",
    "                # Check if neighbor is also a border pixel\n",
    "                if border_mask[ny, nx] == 1:\n",
    "                    neighbor_coords = (ny, nx)\n",
    "                    # Avoid duplicate comparisons\n",
    "                    if (ny, nx) > (y, x):\n",
    "                        neighbor_color = image_lab[ny, nx, :]\n",
    "\n",
    "                        # Compute color difference (CIEDE2000)\n",
    "                        deltaE = deltaE_ciede2000(pixel_color[np.newaxis, :], neighbor_color[np.newaxis, :])[0]\n",
    "\n",
    "                        color_differences.append(deltaE)\n",
    "\n",
    "    color_differences = np.array(color_differences)\n",
    "\n",
    "    if len(color_differences) == 0:\n",
    "        mean_color_difference = 0\n",
    "        std_color_difference = 0\n",
    "        median_color_difference = 0\n",
    "    else:\n",
    "        mean_color_difference = np.mean(color_differences)\n",
    "        std_color_difference = np.std(color_differences)\n",
    "        median_color_difference = np.median(color_differences)\n",
    "\n",
    "    return mean_color_difference, std_color_difference, median_color_difference\n",
    "\n",
    "enc_ref = encoder4()\n",
    "dec_ref = decoder4()\n",
    "matrix_ref = MulLayer('r41')\n",
    "\n",
    "enc_ref.load_state_dict(torch.load('./models/vgg_r41.pth'))\n",
    "dec_ref.load_state_dict(torch.load('./models/dec_r41.pth'))\n",
    "matrix_ref.load_state_dict(torch.load('./models/r41.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "enc_ref_m = encoder_m()\n",
    "enc_ref_m_wo = encoder_m()\n",
    "dec_ref_m = decoder_m()\n",
    "matrix_ref_m = MulLayer_m('r41')\n",
    "\n",
    "enc_ref_m.load_state_dict(torch.load('models/vgg_r41.pth'))\n",
    "enc_ref_m_wo.load_state_dict(torch.load('models/vgg_r41.pth'))\n",
    "dec_ref_m.load_state_dict(torch.load('models/dec_r41.pth'), strict=False)\n",
    "matrix_ref_m.load_state_dict(torch.load('models/r41.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "def partial_convolution(content_im, mask, style_image_file, original_feature_sum=False, feathering=False, penetrate_initial_mask_pixels=0, cookie_cutter=False, index=0):\n",
    "    def visualize_masks(mask_tensors, titles=None, figsize=(12, 6)):\n",
    "        num_masks = len(mask_tensors)\n",
    "        titles = titles or [f'Mask {i+1}' for i in range(num_masks)]\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        for i, mask_tensor in enumerate(mask_tensors):\n",
    "            mask_np = mask_tensor.cpu().numpy()\n",
    "            mask_np = mask_np.squeeze() \n",
    "\n",
    "            plt.subplot(1, num_masks, i + 1)\n",
    "            plt.imshow(mask_np, cmap='gray')\n",
    "            plt.title(titles[i])\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_feature_maps(feature_maps, titles, rows=2, cols=5):\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        for i, feature_map in enumerate(feature_maps):\n",
    "            plt.subplot(rows, cols, i + 1)\n",
    "            feature_map_np = feature_map[0, 222].cpu().detach().numpy()\n",
    "            plt.imshow(feature_map_np, cmap='viridis')\n",
    "            plt.title(titles[i])\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def blend_styled_edges(original_image, styled_image, mask, alpha=0.5):\n",
    "        if isinstance(mask, torch.Tensor):\n",
    "            mask = mask.squeeze().cpu().numpy()\n",
    "\n",
    "        if mask.shape[:2] != original_image.shape[:2]:\n",
    "            mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        if len(mask.shape) == 3 and mask.shape[2] == 1:\n",
    "            mask = mask.squeeze(axis=2)\n",
    "        elif len(mask.shape) == 3 and mask.shape[2] != 1:\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        elif len(mask.shape) != 2:\n",
    "            raise ValueError(\"Mask must be 2D or 3D with one channel.\")\n",
    "\n",
    "        if mask.max() <= 1:\n",
    "            mask = (mask * 255).astype(np.uint8)\n",
    "        else:\n",
    "            mask = mask.astype(np.uint8)\n",
    "\n",
    "        original_image = original_image.astype(np.uint8)\n",
    "        styled_image = styled_image.astype(np.uint8)\n",
    "            \n",
    "        inverse_mask = cv2.bitwise_not(mask)\n",
    "\n",
    "        inverse_masked_original = cv2.bitwise_and(original_image, original_image, mask=inverse_mask)\n",
    "        inverse_masked_original_bordered = apply_border_mask(inverse_masked_original, inverse_mask, 5, border_type='inner')\n",
    "\n",
    "        masked_styled = cv2.bitwise_and(styled_image, styled_image, mask=mask)\n",
    "        inverse_masked_styled = cv2.bitwise_and(styled_image, styled_image, mask=inverse_mask)\n",
    "        masked_styled_outer = apply_border_mask(inverse_masked_styled, mask, 5, border_type='outer')\n",
    "\n",
    "        blended_image = cv2.addWeighted(masked_styled_outer, alpha, inverse_masked_original_bordered, 1 - alpha, 0)\n",
    "        blended_image += inverse_masked_original - inverse_masked_original_bordered\n",
    "        blended_image += masked_styled\n",
    "\n",
    "        return blended_image\n",
    "\n",
    "    masked_im = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "    style_im = cv2.imread(style_image_file)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        #for style, mask in my list\n",
    "        \n",
    "        content_tensor = image_to_tensor(content_im)\n",
    "        style_tensor = image_to_tensor(style_im)\n",
    "\n",
    "        mask_tensor = image_to_tensor(masked_im)\n",
    "        mask_tensor = mask_tensor[:, 0:1, :, :]\n",
    "        \n",
    "        if penetrate_initial_mask_pixels > 0:\n",
    "            cF_ref, small_mask = enc_ref_m(content_tensor, penetrate_mask(mask_tensor, penetrate_initial_mask_pixels), cookie_cutter=cookie_cutter)\n",
    "        else:\n",
    "            cF_ref, small_mask = enc_ref_m(content_tensor, mask_tensor, cookie_cutter=cookie_cutter)\n",
    "                \n",
    "        if original_feature_sum:\n",
    "            cF_ref_orig, _ = enc_ref_m_wo(content_tensor, cookie_cutter=cookie_cutter)\n",
    "        else:\n",
    "            cF_ref_orig = None\n",
    "        sF_ref, _ = enc_ref_m(style_tensor)\n",
    "        \n",
    "        # stylization\n",
    "        feature_ref, _ = matrix_ref_m(cF_ref['r41'], sF_ref['r41'], small_mask)\n",
    "        \n",
    "        # jump out for loop\n",
    "        # for all feature_refs and masks\n",
    "        #    Merge all features_ref through sequential alpha blend\n",
    "        #    Merge all small masks through bitwise or\n",
    "        #    Merge all original masks through bitwise or\n",
    "        \n",
    "        result, mask_conv11, mask_conv12, mask_conv13, mask_conv14, mask_conv15, mask_conv16, mask_conv17, mask_conv18, mask_conv19, out11, out12, out13, out14, out15, out16, out17, out18, out19 = dec_ref_m(feature_ref, small_mask, original_features=cF_ref_orig, feathering=feathering, cookie_cutter=cookie_cutter)\n",
    "    \n",
    "    processed_image_rgb = tensor_to_image(result)\n",
    "    processed_image_rgb = resize_to(processed_image_rgb, content_im)\n",
    "    if feathering:\n",
    "        processed_image_rgb = blend_styled_edges(cv2.cvtColor(content_im, cv2.COLOR_BGR2RGB), processed_image_rgb, mask, alpha=0.5)\n",
    "    else:\n",
    "        processed_image_rgb = regenerate(cv2.cvtColor(content_im, cv2.COLOR_BGR2RGB), processed_image_rgb, mask)\n",
    "\n",
    "    border_mask = get_mask_borders(mask, 3, 5)\n",
    "    halo_metric_mask = get_mask_borders(mask, 9, 0)\n",
    "    \n",
    "    ### GRADIENT MAGNITUDE\n",
    "    mean, std, median = calculate_gradient_magnitude_around_border(processed_image_rgb, border_mask)\n",
    "    _, std_halo, _ = calculate_gradient_magnitude_around_border(processed_image_rgb, halo_metric_mask)\n",
    "    \n",
    "    ### TEXTURE CONTINUITY\n",
    "    mask_borders_inner = get_mask_borders(mask, 3, 0)\n",
    "    mask_borders       = get_mask_borders(mask, 0, 5)\n",
    "    texture_continuity = calculate_texture_continuity(processed_image_rgb, mask_borders_inner, mask_borders)\n",
    "    \n",
    "    ### COLOR CONTINUITY\n",
    "    mean_cc, std_cc, median_cc = calculate_color_continuity_along_border(processed_image_rgb, border_mask)\n",
    "    sum_color_continuity = round(mean_cc, 2) + round(std_cc, 2)\n",
    "    \n",
    "    mean_cc_halo, std_cc_halo, _ = calculate_color_continuity_along_border(processed_image_rgb, halo_metric_mask)\n",
    "    sum_color_continuity_halo = round(mean_cc_halo, 2) + round(std_cc_halo, 2)\n",
    "    \n",
    "    print(f'{i} - {round(mean, 2)} - {round(std, 2)} - {round(mean_cc, 2)} - {round(std_cc, 2)} - {round(sum_color_continuity, 2)} - {round(texture_continuity, 4)} - {round(std_halo, 2)} - {round(sum_color_continuity_halo, 2)}')\n",
    "    \n",
    "    total_style_loss = 0.0  \n",
    "    style_layers = ['r11','r21','r31','r41']\n",
    "    image_tensor = image_to_tensor(processed_image_rgb)  \n",
    "    tF, _ = enc_ref_m(image_tensor, mask_tensor) \n",
    "    \n",
    "    for layer in style_layers:\n",
    "        sf_i = sF_ref[layer]\n",
    "        sf_i = sf_i.detach() \n",
    "        tf_i = tF[layer]\n",
    "        small_mask = generateSmallMask(tf_i, mask_tensor)\n",
    "        total_style_loss += styleLoss(tf_i, sf_i, small_mask)\n",
    "    \n",
    "    #print(\"Total Style Loss:\", total_style_loss.item())\n",
    "    \n",
    "    return processed_image_rgb, round(mean, 2), round(std, 2), round(median, 2), round(total_style_loss.item(), 2) , texture_continuity, sum_color_continuity, round(std_halo, 2), round(sum_color_continuity_halo, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e494fa71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 93.33 - 129.2 - 5.3 - 12.34 - 17.64 - 0.156 - 109.02 - 10.72\n",
      "2 - 96.85 - 139.3 - 5.66 - 14.14 - 19.8 - 0.1208 - 117.27 - 11.61\n",
      "3 - 131.76 - 83.83 - 6.18 - 10.68 - 16.86 - 0.0305 - 110.71 - 13.27\n",
      "4 - 79.2 - 104.33 - 4.27 - 9.63 - 13.9 - 0.1295 - 88.98 - 8.42\n",
      "5 - 103.5 - 83.69 - 5.43 - 8.17 - 13.6 - 0.0986 - 96.17 - 10.72\n",
      "6 - 109.41 - 83.38 - 5.73 - 9.78 - 15.51 - 0.0549 - 100.67 - 11.62\n",
      "7 - 86.65 - 77.75 - 4.16 - 5.93 - 10.09 - 0.0744 - 82.53 - 8.42\n",
      "8 - 118.73 - 161.82 - 6.67 - 15.63 - 22.3 - 0.2051 - 134.02 - 13.29\n",
      "1 - 161.21 - 120.95 - 12.31 - 15.33 - 27.64 - 0.0915 - 91.4 - 10.93\n",
      "2 - 167.98 - 121.37 - 13.15 - 15.75 - 28.9 - 0.1054 - 97.1 - 11.7\n",
      "3 - 126.97 - 95.87 - 8.31 - 9.29 - 17.6 - 0.0571 - 89.11 - 11.61\n",
      "4 - 158.72 - 120.81 - 12.71 - 15.64 - 28.35 - 0.0963 - 93.62 - 11.3\n",
      "5 - 122.69 - 99.01 - 7.73 - 8.92 - 16.65 - 0.0527 - 86.68 - 10.93\n",
      "6 - 115.99 - 99.13 - 7.97 - 9.01 - 16.98 - 0.0566 - 92.56 - 11.7\n",
      "7 - 117.6 - 98.93 - 7.85 - 8.96 - 16.81 - 0.0353 - 89.39 - 11.3\n",
      "8 - 173.54 - 121.6 - 13.17 - 16.15 - 29.32 - 0.0812 - 96.98 - 11.61\n",
      "1 - 206.98 - 137.27 - 8.71 - 10.52 - 19.23 - 0.1622 - 110.53 - 8.74\n",
      "2 - 205.26 - 135.61 - 8.71 - 10.53 - 19.24 - 0.1595 - 109.14 - 8.63\n",
      "3 - 153.42 - 80.85 - 6.29 - 6.52 - 12.81 - 0.0847 - 77.93 - 8.7\n",
      "4 - 203.73 - 134.1 - 8.69 - 10.47 - 19.16 - 0.1673 - 108.79 - 8.7\n",
      "5 - 151.48 - 82.89 - 6.21 - 6.38 - 12.59 - 0.0947 - 79.85 - 8.74\n",
      "6 - 151.22 - 80.85 - 6.36 - 6.47 - 12.83 - 0.1058 - 79.21 - 8.63\n",
      "7 - 150.34 - 82.61 - 6.15 - 6.43 - 12.58 - 0.1035 - 80.49 - 8.7\n",
      "8 - 211.84 - 140.43 - 8.96 - 10.75 - 19.71 - 0.1472 - 111.79 - 8.7\n",
      "1 - 170.08 - 142.56 - 12.53 - 15.8 - 28.33 - 0.0616 - 105.94 - 10.65\n",
      "2 - 175.13 - 142.1 - 13.31 - 15.51 - 28.82 - 0.0528 - 115.73 - 10.77\n",
      "3 - 123.56 - 100.59 - 6.72 - 7.27 - 13.99 - 0.032 - 89.18 - 10.39\n",
      "4 - 174.61 - 139.57 - 13.34 - 15.25 - 28.59 - 0.0585 - 114.86 - 10.73\n",
      "5 - 119.54 - 98.22 - 6.56 - 7.08 - 13.64 - 0.031 - 89.15 - 10.65\n",
      "6 - 117.11 - 89.03 - 7.27 - 7.55 - 14.82 - 0.0292 - 98.89 - 10.77\n",
      "7 - 119.63 - 89.21 - 7.41 - 7.75 - 15.16 - 0.0307 - 99.27 - 10.73\n",
      "8 - 175.87 - 148.94 - 12.8 - 16.34 - 29.14 - 0.0706 - 110.8 - 10.39\n",
      "1 - 123.59 - 104.93 - 8.2 - 10.73 - 18.93 - 0.2006 - 89.76 - 9.14\n",
      "2 - 135.39 - 118.97 - 8.64 - 11.8 - 20.44 - 0.2147 - 100.46 - 9.23\n",
      "3 - 139.02 - 76.18 - 7.73 - 7.96 - 15.69 - 0.0491 - 78.05 - 10.84\n",
      "4 - 142.6 - 124.69 - 9.08 - 12.45 - 21.53 - 0.2383 - 103.68 - 9.35\n",
      "5 - 114.01 - 65.06 - 7.1 - 6.89 - 13.99 - 0.1214 - 72.65 - 9.14\n",
      "6 - 108.41 - 73.51 - 5.52 - 5.85 - 11.37 - 0.1035 - 79.87 - 9.22\n",
      "7 - 113.34 - 74.8 - 5.66 - 6.15 - 11.81 - 0.1117 - 80.67 - 9.35\n",
      "8 - 134.27 - 116.08 - 9.4 - 12.49 - 21.89 - 0.2565 - 94.35 - 10.84\n",
      "1 - 301.85 - 187.31 - 23.7 - 24.11 - 47.81 - 0.2761 - 145.92 - 8.42\n",
      "2 - 264.59 - 172.51 - 22.13 - 22.45 - 44.58 - 0.2466 - 123.41 - 8.82\n",
      "3 - 196.37 - 120.12 - 9.83 - 9.4 - 19.23 - 0.1941 - 87.3 - 7.79\n",
      "4 - 260.08 - 170.15 - 21.86 - 22.02 - 43.88 - 0.231 - 120.89 - 8.78\n",
      "5 - 193.68 - 119.71 - 9.76 - 9.3 - 19.06 - 0.2029 - 84.19 - 8.42\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pycocotools import mask as mask_utils\n",
    "import random\n",
    "\n",
    "# Directory path\n",
    "data_dir = '/Users/ayberk.cansever/Documents/ECU/Thesis/SAM/dataset'\n",
    "\n",
    "def decode_rle(rle, shape):\n",
    "    binary_mask = mask_utils.decode(rle)\n",
    "    return binary_mask\n",
    "\n",
    "def extract_large_mask(data, shape, min_area):\n",
    "    largest_mask = None\n",
    "    largest_area = 0\n",
    "    stability_score = 0\n",
    "    \n",
    "    for annotation in data.get(\"annotations\", []):\n",
    "        rle = annotation.get(\"segmentation\")\n",
    "        stability_score = annotation.get(\"stability_score\")\n",
    "        if rle:\n",
    "            binary_mask = decode_rle(rle, shape)\n",
    "            mask_area = np.sum(binary_mask)\n",
    "            \n",
    "            # Return the binary mask as an OpenCV-compatible image if it meets the min_area requirement\n",
    "            if mask_area >= min_area:\n",
    "                return (binary_mask * 255).astype(np.uint8), stability_score \n",
    "            \n",
    "            if mask_area > largest_area:\n",
    "                largest_area = mask_area\n",
    "                largest_mask = binary_mask            \n",
    "                \n",
    "    # If no mask meets min_area, return the largest one in OpenCV format\n",
    "    if largest_mask is not None:\n",
    "        return (largest_mask * 255).astype(np.uint8), stability_score\n",
    "    else:\n",
    "        return None, None  # Return None if no masks are available\n",
    "\n",
    "#style_image_files = [cv2.cvtColor(cv2.imread(f'./styles/style-{i}.jpg'), cv2.COLOR_BGR2RGB) for i in range(8)]\n",
    "style_image_files = [f'./results/styles/style-{i}.jpg' for i in range(6)]\n",
    "\n",
    "feature_combinations = [\n",
    "    {\"cookie_cutter\": True, \"penetrate_initial_mask_pixels\": 0, \"feathering\": False},   #1 o,x,x\n",
    "    {\"cookie_cutter\": False, \"penetrate_initial_mask_pixels\": 7, \"feathering\": False},  #2 x,o,x\n",
    "    {\"cookie_cutter\": False, \"penetrate_initial_mask_pixels\": 0, \"feathering\": True},   #3 x,x,o\n",
    "    {\"cookie_cutter\": True, \"penetrate_initial_mask_pixels\": 7, \"feathering\": False},   #4 o,o,x\n",
    "    {\"cookie_cutter\": True, \"penetrate_initial_mask_pixels\": 0, \"feathering\": True},    #5 o,x,o\n",
    "    {\"cookie_cutter\": False, \"penetrate_initial_mask_pixels\": 7, \"feathering\": True},   #6 x,o,o\n",
    "    {\"cookie_cutter\": True, \"penetrate_initial_mask_pixels\": 7, \"feathering\": True},    #7 o,o,o\n",
    "    {\"cookie_cutter\": False, \"penetrate_initial_mask_pixels\": 0, \"feathering\": False}   #8 x,x,x\n",
    "]\n",
    "\n",
    "# Initialize output file\n",
    "output_file = \"./results/gradient_style_report.csv\"\n",
    "with open(output_file, \"w\") as report_file:\n",
    "    report_file.write(\"Feature_Combination,Filename,Style,Stability_Score,Mean_Gradient,Std_Gradient,Text_Continuity,Color_Continuity,Std_Halo,Color_Continuity_Halo,Total_Style_Loss\\n\")\n",
    "\n",
    "# Loop through images\n",
    "for img_index in range(101, 151):\n",
    "    file = f\"sa_{img_index}.jpg\"\n",
    "    filename = file.replace('.jpg', '')\n",
    "    img_path = os.path.join(data_dir, file)\n",
    "    json_path = img_path.replace('.jpg', '.json')\n",
    "    \n",
    "    # Load the image and mask\n",
    "    image_to_be_processed = cv2.imread(img_path)\n",
    "    if image_to_be_processed is None:\n",
    "        print(f\"Image {file} not found. Skipping.\")\n",
    "        continue\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        width = data[\"image\"][\"width\"]\n",
    "        height = data[\"image\"][\"height\"]\n",
    "        image_area = width * height\n",
    "        min_area = image_area * 0.05\n",
    "        mask, stability_score = extract_large_mask(data, (height, width), min_area)\n",
    "        \n",
    "        if mask is None:\n",
    "            print(f\"No mask found for {file}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        #style_image_filename = random.choice(style_image_files)\n",
    "        style_image_filename = './results/styles/style-4.jpg'\n",
    "        style_image = cv2.cvtColor(cv2.imread(style_image_filename), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Apply each feature combination\n",
    "        for i, features in enumerate(feature_combinations, 1):\n",
    "            #print(f\"{filename} - Feature combination {i} process started...\")\n",
    "            \n",
    "            # Process the image with partial_convolution\n",
    "            processed_image, mean, std, median, total_style_loss, texture_continuity, sum_color_continuity, std_halo, sum_color_continuity_halo = partial_convolution(\n",
    "                image_to_be_processed, \n",
    "                mask, \n",
    "                style_image_filename, \n",
    "                feathering=features[\"feathering\"], \n",
    "                penetrate_initial_mask_pixels=features[\"penetrate_initial_mask_pixels\"],\n",
    "                cookie_cutter=features[\"cookie_cutter\"],\n",
    "                index=i\n",
    "            )\n",
    "            \n",
    "            # Save the processed image\n",
    "            cv2.imwrite(f'./results/{filename}_feature_{i}.jpg', cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            # Log the results\n",
    "            with open(output_file, \"a\") as report_file:\n",
    "                report_file.write(f\"{i},{filename},{style_image_filename},{stability_score},{mean},{std},{texture_continuity},{sum_color_continuity},{std_halo},{sum_color_continuity_halo},{total_style_loss}\\n\")\n",
    "            \n",
    "            #print(f\"{filename} - Feature combination {i} process completed and saved.\")\n",
    "\n",
    "print(\"Processing complete. Report saved to\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"./results/8/gradient_style_report.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "average_std_gradient = round(df.groupby('Feature_Combination')['Std_Gradient'].mean(), 2)\n",
    "print(average_std_gradient)\n",
    "\n",
    "average_text_continuity = round(df.groupby('Feature_Combination')['Text_Continuity'].mean(), 4)\n",
    "print(average_text_continuity)\n",
    "\n",
    "average_color_continuity = round(df.groupby('Feature_Combination')['Color_Continuity'].mean(), 4)\n",
    "print(average_color_continuity)\n",
    "\n",
    "correlation_columns = ['Std_Gradient', 'Text_Continuity', 'Color_Continuity']\n",
    "correlation_matrix = df[correlation_columns].corr()\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a new metric to calculate Halo effect (9 pixels inside border)\n",
    "# multi mask, multi style (merge masks, sequential alpha blend the features) to the decoder\n",
    "# 3D Earth movers distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
