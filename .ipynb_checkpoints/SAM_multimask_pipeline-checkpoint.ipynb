{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a22cae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "import scipy.ndimage\n",
    "import torchvision\n",
    "\n",
    "interactive_fig = None\n",
    "interactive_fig_styles = None\n",
    "\n",
    "def plot_images(images, titles, figure_size):\n",
    "    #%matplotlib inline\n",
    "    if interactive_fig is not None:\n",
    "        plt.close(interactive_fig)\n",
    "    if interactive_fig_styles is not None:\n",
    "        plt.close(interactive_fig_styles)\n",
    "    plt.figure(figsize=(figure_size, figure_size))\n",
    "    for i in range(len(images)):\n",
    "        image = images[i]\n",
    "        title = titles[i]\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "\n",
    "def resize_to(image, target):\n",
    "    target_height, target_width = target.shape[:2]\n",
    "    image = cv2.resize(image, (target_width, target_height), interpolation=cv2.INTER_LINEAR)\n",
    "    return image\n",
    "\n",
    "def regenerate(org_image, masked_image, mask):\n",
    "    if isinstance(mask, torch.Tensor):\n",
    "        mask = mask.squeeze().cpu().numpy().astype(np.uint8) * 255\n",
    "        mask = cv2.resize(mask, (org_image.shape[1], org_image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        mask = mask.astype(np.uint8)\n",
    "        \n",
    "    inverse_mask = cv2.bitwise_not(mask)\n",
    "    masked_original = cv2.bitwise_and(org_image, org_image, mask=inverse_mask)\n",
    "    styled_masked = cv2.bitwise_and(masked_image, masked_image, mask=mask)\n",
    "    return cv2.add(masked_original, styled_masked) \n",
    "\n",
    "def plot_tensor_image(tensor):\n",
    "    if tensor.is_cuda:\n",
    "        tensor = tensor.cpu()\n",
    "    \n",
    "    tensor = tensor.detach()\n",
    "    \n",
    "    if tensor.dim() == 4 and tensor.size(0) == 1 and tensor.size(1) == 1:\n",
    "        tensor = tensor.squeeze(0).squeeze(0)  \n",
    "        plt.imshow(tensor.numpy(), cmap='gray')\n",
    "    elif tensor.dim() == 3 and tensor.size(0) == 1:\n",
    "        tensor = tensor.squeeze(0)\n",
    "        plt.imshow(tensor.numpy(), cmap='gray')\n",
    "    elif tensor.dim() == 3 and tensor.size(0) in [1, 3]:\n",
    "        tensor = tensor.permute(1, 2, 0).numpy()\n",
    "        tensor = (tensor - tensor.min()) / (tensor.max() - tensor.min()) \n",
    "        plt.imshow(tensor)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected tensor shape: {tensor.shape}\")\n",
    "\n",
    "    plt.axis('off')  # Hide axis\n",
    "    plt.show()\n",
    "\n",
    "def extract_borders(mask, border_thickness, border_type='inner'):\n",
    "    binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    kernel = np.ones((border_thickness, border_thickness), np.uint8)\n",
    "    \n",
    "    if border_type == 'inner':\n",
    "        # Erode the mask for inner borders\n",
    "        eroded_mask = cv2.erode(binary_mask, kernel, iterations=1)\n",
    "        border_mask = binary_mask - eroded_mask\n",
    "    elif border_type == 'outer':\n",
    "        # Dilate the mask for outer borders\n",
    "        dilated_mask = cv2.dilate(binary_mask, kernel, iterations=1)\n",
    "        border_mask = dilated_mask - binary_mask\n",
    "    elif border_type == 'both':\n",
    "        # Extract both inner and outer borders\n",
    "        eroded_mask = cv2.erode(binary_mask, kernel, iterations=1)\n",
    "        inner_border_mask = binary_mask - eroded_mask\n",
    "        \n",
    "        dilated_mask = cv2.dilate(binary_mask, kernel, iterations=1)\n",
    "        outer_border_mask = dilated_mask - binary_mask\n",
    "        \n",
    "        # Combine inner and outer borders\n",
    "        border_mask = cv2.bitwise_or(inner_border_mask, outer_border_mask)\n",
    "    else:\n",
    "        raise ValueError(\"border_type must be either 'inner', 'outer', or 'both'\")\n",
    "    \n",
    "    return border_mask\n",
    "\n",
    "def apply_border_mask(image, mask, border_thickness, border_type='inner'):\n",
    "    border_mask = extract_borders(mask, border_thickness, border_type=border_type)\n",
    "    border_mask_3channel = cv2.merge([border_mask]*3)\n",
    "    border_extracted_image = cv2.bitwise_and(image, border_mask_3channel)\n",
    "    return border_extracted_image\n",
    "    \n",
    "def penetrate_mask(mask, radius, shrink=0):\n",
    "    import scipy.ndimage \n",
    "    import numpy as np\n",
    "\n",
    "    mask = mask.float()\n",
    "    mask_np = mask.squeeze(0).cpu().numpy() \n",
    "\n",
    "    if shrink > 0:\n",
    "        eroded_mask_np = scipy.ndimage.binary_erosion(mask_np, iterations=shrink).astype(mask_np.dtype)\n",
    "    else:\n",
    "        eroded_mask_np = mask_np\n",
    "\n",
    "    distance_map = scipy.ndimage.distance_transform_edt(eroded_mask_np == 0)\n",
    "    penetration_mask_np = np.clip((radius - distance_map) / radius, 0, 1)\n",
    "    penetration_mask = torch.tensor(penetration_mask_np, device=mask.device, dtype=mask.dtype).unsqueeze(0)\n",
    "\n",
    "    return penetration_mask \n",
    "\n",
    "def get_mask_borders(mask, inside_pixels, outside_pixels):\n",
    "    mask = (mask > 0).astype(np.uint8)\n",
    "    inside_eroded = cv2.erode(mask, np.ones((inside_pixels, inside_pixels), np.uint8)) if inside_pixels > 0 else mask\n",
    "    outside_dilated = cv2.dilate(mask, np.ones((outside_pixels, outside_pixels), np.uint8)) if outside_pixels > 0 else mask\n",
    "    border_mask = outside_dilated - inside_eroded\n",
    "    return border_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aec9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "from libs import Matrix, models, Matrix_masked, models_masked\n",
    "from libs.Matrix import MulLayer\n",
    "from libs.models import encoder4, decoder4\n",
    "from libs.Matrix_masked import MulLayer as MulLayer_m\n",
    "from libs.models_masked import encoder4 as encoder_m, decoder4 as decoder_m\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from skimage.feature import local_binary_pattern\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import chisquare\n",
    "from skimage.color import rgb2lab\n",
    "from skimage.color import deltaE_ciede2000\n",
    "\n",
    "def generateSmallMask(x, mask):\n",
    "    b, c, h, w = x.shape\n",
    "    small_mask = mask\n",
    "    small_mask = torch.nn.functional.interpolate(small_mask, size=(h, w), mode='bilinear', align_corners=False)\n",
    "    return small_mask.squeeze(0)\n",
    "\n",
    "def gramMatrix(features):\n",
    "    # Assumes flattened input\n",
    "    b, c, l = features.size()\n",
    "    G = torch.bmm(features,features.transpose(1,2)) # f: bxcx(hxw), f.transpose: bx(hxw)xc -> bxcxc\n",
    "    return G.div_(c*l)\n",
    "\n",
    "def styleLoss(features,target,mask):\n",
    "    ib,ic,ih,iw = features.size()\n",
    "    iF = features.view(ib,ic,-1)\n",
    "    imask = mask.view(ib,1,-1)\n",
    "    iF = iF.masked_select(imask.expand_as(iF) > 0)\n",
    "    iF = iF.view(ib, ic, -1)\n",
    "    iMean = torch.mean(iF,dim=2)\n",
    "    iCov = gramMatrix(iF)\n",
    "\n",
    "    tb,tc,th,tw = target.size()\n",
    "    tF = target.view(tb,tc,-1)\n",
    "    tMean = torch.mean(tF,dim=2)\n",
    "    tCov = gramMatrix(tF)\n",
    "\n",
    "    loss = torch.nn.MSELoss(reduction=\"sum\")(iMean,tMean) + torch.nn.MSELoss(reduction=\"sum\")(iCov,tCov)\n",
    "    return loss/tb\n",
    "\n",
    "def image_to_tensor(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_tensor = F.to_tensor(image)\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    return image_tensor\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor.squeeze(0)\n",
    "    image = tensor.detach().cpu().numpy()\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    image = (image * 255).clip(0, 255).astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "def calculate_gradient_magnitude_around_border(image, mask):\n",
    "    if len(mask.shape) == 3:\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask = (mask > 0).astype(np.uint8)\n",
    "    \n",
    "    grad_magnitudes = []\n",
    "    for c in range(3): \n",
    "        grad_x = cv2.Sobel(image[:, :, c], cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(image[:, :, c], cv2.CV_64F, 0, 1, ksize=3)\n",
    "        grad_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "        grad_magnitudes.append(grad_magnitude)\n",
    "    \n",
    "    # Combine gradient magnitudes across channels1\n",
    "    gradient_magnitude = np.mean(grad_magnitudes, axis=0)\n",
    "    \n",
    "    # Apply the mask to isolate the border\n",
    "    border_gradient_magnitude = gradient_magnitude * mask\n",
    "    border_pixels = border_gradient_magnitude[mask > 0]\n",
    "\n",
    "    mean_gradient = np.mean(border_pixels)\n",
    "    std_gradient = np.std(border_pixels)\n",
    "    median_gradient = np.median(border_pixels)\n",
    "    return mean_gradient, std_gradient, median_gradient\n",
    "\n",
    "def calculate_texture_continuity(blended_image, inner_border_mask, outer_border_mask, radius=1, n_points=8):\n",
    "    inner_border_mask = (inner_border_mask > 0).astype(np.uint8)\n",
    "    outer_border_mask = (outer_border_mask > 0).astype(np.uint8)\n",
    "    \n",
    "    lbp_histograms_inner = []\n",
    "    lbp_histograms_outer = []\n",
    "    \n",
    "    # Process each color channel\n",
    "    for c in range(3): \n",
    "        channel_image = blended_image[:, :, c]\n",
    "        lbp_image = local_binary_pattern(channel_image, n_points, radius, method='uniform')\n",
    "        \n",
    "        # Extract LBP values within the inner and outer masks\n",
    "        inner_area = lbp_image[inner_border_mask > 0]\n",
    "        outer_area = lbp_image[outer_border_mask > 0]\n",
    "        \n",
    "        # Calculate histograms for each channel\n",
    "        bins = np.arange(0, n_points + 3)\n",
    "        inner_hist, _ = np.histogram(inner_area, bins=bins)\n",
    "        outer_hist, _ = np.histogram(outer_area, bins=bins)\n",
    "        \n",
    "        lbp_histograms_inner.append(inner_hist)\n",
    "        lbp_histograms_outer.append(outer_hist)\n",
    "    \n",
    "    # Combine histograms from all channels\n",
    "    inner_hist_total = np.concatenate(lbp_histograms_inner)\n",
    "    outer_hist_total = np.concatenate(lbp_histograms_outer)\n",
    "    \n",
    "    # Normalize histograms\n",
    "    eps = 1e-10\n",
    "    inner_hist_total = inner_hist_total.astype(np.float32)\n",
    "    outer_hist_total = outer_hist_total.astype(np.float32)\n",
    "    inner_hist_total /= (inner_hist_total.sum() + eps)\n",
    "    outer_hist_total /= (outer_hist_total.sum() + eps)\n",
    "    \n",
    "    # Compute Chi-square distance\n",
    "    chi2_distance = 0.5 * np.sum(((inner_hist_total - outer_hist_total) ** 2) / (inner_hist_total + outer_hist_total + eps))\n",
    "    \n",
    "    return chi2_distance\n",
    "\n",
    "def calculate_color_continuity_along_border(image, border_mask):\n",
    "    \n",
    "    border_mask = (border_mask > 0).astype(np.uint8)\n",
    "\n",
    "    border_coords = np.column_stack(np.where(border_mask == 1))\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    color_differences = []\n",
    "\n",
    "    # Define 8-connected neighborhood offsets\n",
    "    offsets = [(-1, -1), (-1, 0), (-1, 1),\n",
    "               (0, -1),          (0, 1),\n",
    "               (1, -1),  (1, 0), (1, 1)]\n",
    "\n",
    "    border_pixel_set = set(map(tuple, border_coords))\n",
    "\n",
    "    for y, x in border_coords:\n",
    "        pixel_color = image_lab[y, x, :]\n",
    "\n",
    "        for dy, dx in offsets:\n",
    "            ny, nx = y + dy, x + dx\n",
    "\n",
    "            # Check if neighbor is within image bounds\n",
    "            if 0 <= ny < border_mask.shape[0] and 0 <= nx < border_mask.shape[1]:\n",
    "                # Check if neighbor is also a border pixel\n",
    "                if border_mask[ny, nx] == 1:\n",
    "                    neighbor_coords = (ny, nx)\n",
    "                    # Avoid duplicate comparisons\n",
    "                    if (ny, nx) > (y, x):\n",
    "                        neighbor_color = image_lab[ny, nx, :]\n",
    "\n",
    "                        # Compute color difference (CIEDE2000)\n",
    "                        deltaE = deltaE_ciede2000(pixel_color[np.newaxis, :], neighbor_color[np.newaxis, :])[0]\n",
    "\n",
    "                        color_differences.append(deltaE)\n",
    "\n",
    "    color_differences = np.array(color_differences)\n",
    "\n",
    "    if len(color_differences) == 0:\n",
    "        mean_color_difference = 0\n",
    "        std_color_difference = 0\n",
    "        median_color_difference = 0\n",
    "    else:\n",
    "        mean_color_difference = np.mean(color_differences)\n",
    "        std_color_difference = np.std(color_differences)\n",
    "        median_color_difference = np.median(color_differences)\n",
    "\n",
    "    return mean_color_difference, std_color_difference, median_color_difference\n",
    "\n",
    "enc_ref = encoder4()\n",
    "dec_ref = decoder4()\n",
    "matrix_ref = MulLayer('r41')\n",
    "\n",
    "enc_ref.load_state_dict(torch.load('./models/vgg_r41.pth'))\n",
    "dec_ref.load_state_dict(torch.load('./models/dec_r41.pth'))\n",
    "matrix_ref.load_state_dict(torch.load('./models/r41.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "enc_ref_m = encoder_m()\n",
    "enc_ref_m_wo = encoder_m()\n",
    "dec_ref_m = decoder_m()\n",
    "matrix_ref_m = MulLayer_m('r41')\n",
    "\n",
    "enc_ref_m.load_state_dict(torch.load('models/vgg_r41.pth'))\n",
    "enc_ref_m_wo.load_state_dict(torch.load('models/vgg_r41.pth'))\n",
    "dec_ref_m.load_state_dict(torch.load('models/dec_r41.pth'), strict=False)\n",
    "matrix_ref_m.load_state_dict(torch.load('models/r41.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "def partial_convolution(content_im, masks, style_image_files, feathering=False, penetrate_initial_mask_pixels=0, cookie_cutter=False, index=0, resize_style_image=False):\n",
    "    def visualize_masks(mask_tensors, titles=None, figsize=(12, 6)):\n",
    "        num_masks = len(mask_tensors)\n",
    "        titles = titles or [f'Mask {i+1}' for i in range(num_masks)]\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        for i, mask_tensor in enumerate(mask_tensors):\n",
    "            mask_np = mask_tensor.cpu().numpy()\n",
    "            mask_np = mask_np.squeeze() \n",
    "\n",
    "            plt.subplot(1, num_masks, i + 1)\n",
    "            plt.imshow(mask_np, cmap='gray')\n",
    "            plt.title(titles[i])\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_feature_maps(feature_maps, titles, rows=2, cols=5):\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        for i, feature_map in enumerate(feature_maps):\n",
    "            plt.subplot(rows, cols, i + 1)\n",
    "            feature_map_np = feature_map[0, 222].cpu().detach().numpy()\n",
    "            plt.imshow(feature_map_np, cmap='viridis')\n",
    "            plt.title(titles[i])\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def blend_styled_edges(original_image, styled_image, mask, alpha=0.5):\n",
    "        if isinstance(mask, torch.Tensor):\n",
    "            mask = mask.squeeze().cpu().numpy()\n",
    "\n",
    "        if mask.shape[:2] != original_image.shape[:2]:\n",
    "            mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        if len(mask.shape) == 3 and mask.shape[2] == 1:\n",
    "            mask = mask.squeeze(axis=2)\n",
    "        elif len(mask.shape) == 3 and mask.shape[2] != 1:\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        elif len(mask.shape) != 2:\n",
    "            raise ValueError(\"Mask must be 2D or 3D with one channel.\")\n",
    "\n",
    "        if mask.max() <= 1:\n",
    "            mask = (mask * 255).astype(np.uint8)\n",
    "        else:\n",
    "            mask = mask.astype(np.uint8)\n",
    "\n",
    "        original_image = original_image.astype(np.uint8)\n",
    "        styled_image = styled_image.astype(np.uint8)\n",
    "            \n",
    "        inverse_mask = cv2.bitwise_not(mask)\n",
    "\n",
    "        inverse_masked_original = cv2.bitwise_and(original_image, original_image, mask=inverse_mask)\n",
    "        inverse_masked_original_bordered = apply_border_mask(inverse_masked_original, inverse_mask, 5, border_type='inner')\n",
    "\n",
    "        masked_styled = cv2.bitwise_and(styled_image, styled_image, mask=mask)\n",
    "        inverse_masked_styled = cv2.bitwise_and(styled_image, styled_image, mask=inverse_mask)\n",
    "        masked_styled_outer = apply_border_mask(inverse_masked_styled, mask, 5, border_type='outer')\n",
    "\n",
    "        blended_image = cv2.addWeighted(masked_styled_outer, alpha, inverse_masked_original_bordered, 1 - alpha, 0)\n",
    "        blended_image += inverse_masked_original - inverse_masked_original_bordered\n",
    "        blended_image += masked_styled\n",
    "\n",
    "        return blended_image\n",
    "    \n",
    "    def resize_style_image_to_mask(mask, style_im):\n",
    "        if len(mask.shape) == 3 and mask.shape[2] == 3:\n",
    "            gray_mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY) \n",
    "        else:\n",
    "            gray_mask = mask \n",
    "\n",
    "        _, binary_mask = cv2.threshold(gray_mask, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        non_zero_pixels = cv2.findNonZero(binary_mask)  # Find all non-zero pixel coordinates\n",
    "        x, y, w, h = cv2.boundingRect(non_zero_pixels)  # Compute bounding box (x, y, width, height)\n",
    "        style_h, style_w = style_im.shape[:2]\n",
    "        scale_factor = min(h / style_h, w / style_w)\n",
    "        new_style_h = int(style_h * scale_factor)\n",
    "        new_style_w = int(style_w * scale_factor)\n",
    "        resized_style_im = cv2.resize(style_im, (new_style_w, new_style_h), interpolation=cv2.INTER_AREA)\n",
    "        return resized_style_im\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        content_tensor = image_to_tensor(content_im)\n",
    "        \n",
    "        feature_refs = []\n",
    "        small_masks = []\n",
    "        mask_tensors = []\n",
    "\n",
    "        # STEP-1 PROCESS EACH MASK AND STYLE\n",
    "        for i in range(len(masks)):\n",
    "            enc_ref_m = encoder_m()\n",
    "            enc_ref_m.load_state_dict(torch.load('models/vgg_r41.pth'))\n",
    "            matrix_ref_m = MulLayer_m('r41')\n",
    "            matrix_ref_m.load_state_dict(torch.load('models/r41.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "            mask = masks[i]\n",
    "            masked_im = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "            style_im = cv2.imread(style_image_files[i])\n",
    "\n",
    "            if resize_style_image:\n",
    "                style_im = resize_style_image_to_mask(mask, style_im)\n",
    "\n",
    "            # Convert the style image and mask to tensors\n",
    "            style_tensor = image_to_tensor(style_im)\n",
    "            mask_tensor = image_to_tensor(masked_im)[:, 0:1, :, :]\n",
    "\n",
    "            # Process with initial mask adjustment if necessary\n",
    "            if penetrate_initial_mask_pixels > 0:\n",
    "                cF_ref, small_mask = enc_ref_m(\n",
    "                    content_tensor,\n",
    "                    penetrate_mask(mask_tensor, penetrate_initial_mask_pixels),\n",
    "                    cookie_cutter=cookie_cutter)\n",
    "            else:\n",
    "                cF_ref, small_mask = enc_ref_m(\n",
    "                    content_tensor, mask_tensor, cookie_cutter=cookie_cutter)\n",
    "\n",
    "            # Encode the style tensor\n",
    "            sF_ref, _ = enc_ref_m(style_tensor)\n",
    "\n",
    "            # Transfer style using the matrix module\n",
    "            feature_ref, _ = matrix_ref_m(cF_ref['r41'], sF_ref['r41'], small_mask)\n",
    "\n",
    "            # Append results to the lists\n",
    "            feature_refs.append(feature_ref)\n",
    "            small_masks.append(small_mask)\n",
    "            mask_tensors.append(mask_tensor)\n",
    "\n",
    "        # STEP-2 EXPANDING MASKS TO MATCH FEATURE MAP DIMENSIONS\n",
    "        expanded_masks = []\n",
    "        for mask in small_masks:\n",
    "            expanded_mask = mask.expand_as(feature_refs[0])\n",
    "            expanded_masks.append(expanded_mask)\n",
    "\n",
    "        # STEP-3 MERGING FEATURES\n",
    "        merged_feature_ref = torch.zeros_like(feature_refs[0])\n",
    "        sum_weights = torch.zeros_like(expanded_masks[0])\n",
    "\n",
    "        normalized_masks = [mask / mask.max() for mask in small_masks]\n",
    "        expanded_masks = [mask.expand_as(feature_refs[0]) for mask in normalized_masks]\n",
    "\n",
    "        for i in range(len(feature_refs)):\n",
    "            merged_feature_ref += feature_refs[i] * expanded_masks[i]\n",
    "            sum_weights += expanded_masks[i]\n",
    "\n",
    "        epsilon = 1e-8\n",
    "        sum_weights = torch.clamp(sum_weights, min=epsilon)\n",
    "        merged_feature_ref /= sum_weights\n",
    "        \n",
    "        total_mask = torch.zeros_like(mask_tensors[0])\n",
    "        for mask in mask_tensors:\n",
    "            total_mask += mask\n",
    "        if (total_mask > 1).any():\n",
    "            print(\"Warning: Masks are overlapping.\")\n",
    "        \n",
    "        # STEP-4 MERGING SMALL MASK TENSORS\n",
    "        merged_small_mask_tensor = small_masks[0]\n",
    "        for i in range(1, len(small_masks)):\n",
    "            merged_small_mask_tensor = torch.max(merged_small_mask_tensor, small_masks[i])\n",
    "        \n",
    "        # STEP-5 MERGING ORIGINAL MASK TENSORS\n",
    "        merged_mask_tensor = mask_tensors[0]\n",
    "        for i in range(1, len(mask_tensors)):\n",
    "            merged_mask_tensor = torch.max(merged_mask_tensor, mask_tensors[i])\n",
    "\n",
    "        # STEP-6 DECODING\n",
    "        result, mask_conv11, mask_conv12, mask_conv13, mask_conv14, mask_conv15, mask_conv16, mask_conv17, mask_conv18, mask_conv19, out11, out12, out13, out14, out15, out16, out17, out18, out19 = dec_ref_m(\n",
    "            merged_feature_ref,\n",
    "            merged_small_mask_tensor,\n",
    "            feathering=feathering,\n",
    "            cookie_cutter=cookie_cutter)\n",
    "        \n",
    "    processed_image_rgb = tensor_to_image(result)\n",
    "    processed_image_rgb = resize_to(processed_image_rgb, content_im)\n",
    "    if feathering:\n",
    "        processed_image_rgb = blend_styled_edges(cv2.cvtColor(content_im, cv2.COLOR_BGR2RGB), processed_image_rgb, merged_mask_tensor, alpha=0.5)\n",
    "    else:\n",
    "        processed_image_rgb = regenerate(cv2.cvtColor(content_im, cv2.COLOR_BGR2RGB), processed_image_rgb, merged_mask_tensor)\n",
    "\n",
    "    return processed_image_rgb, merged_mask_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e494fa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pycocotools import mask as mask_utils\n",
    "import random\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "from itertools import combinations\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy import ndimage\n",
    "\n",
    "data_dir = '/Users/ayberk.cansever/Documents/ECU/Thesis/SAM/dataset'\n",
    "\n",
    "def decode_rle(rle, shape):\n",
    "    binary_mask = mask_utils.decode(rle)\n",
    "    return binary_mask\n",
    "\n",
    "def extract_closest_masks(data, shape, min_area, num_masks_to_return):\n",
    "    masks = []\n",
    "    centroids = []\n",
    "    \n",
    "    for annotation in data.get(\"annotations\", []):\n",
    "        rle = annotation.get(\"segmentation\")\n",
    "        if rle:\n",
    "            binary_mask = decode_rle(rle, shape)\n",
    "            mask_area = np.sum(binary_mask)\n",
    "            if mask_area >= min_area:\n",
    "                binary_mask = binary_mask.astype(np.uint8)\n",
    "                masks.append(binary_mask)\n",
    "                # Calculate centroid\n",
    "                moments = cv2.moments(binary_mask)\n",
    "                if moments['m00'] != 0:\n",
    "                    cx = int(moments['m10'] / moments['m00'])\n",
    "                    cy = int(moments['m01'] / moments['m00'])\n",
    "                else:\n",
    "                    cx, cy = shape[1] // 2, shape[0] // 2 \n",
    "                centroids.append((cx, cy))\n",
    "    \n",
    "    total_masks = len(masks)\n",
    "    \n",
    "    if total_masks == 0:\n",
    "        empty_mask = np.zeros(shape, dtype=np.uint8)\n",
    "        return [empty_mask for _ in range(num_masks_to_return)]\n",
    "    \n",
    "    centroids_array = np.array(centroids)\n",
    "    pairwise_distances = squareform(pdist(centroids_array, metric='euclidean'))\n",
    "\n",
    "    mask_overlaps = np.zeros((total_masks, total_masks), dtype=bool)\n",
    "    for i in range(total_masks):\n",
    "        for j in range(i + 1, total_masks):\n",
    "            overlap = np.logical_and(masks[i], masks[j])\n",
    "            if np.any(overlap):\n",
    "                mask_overlaps[i, j] = True\n",
    "                mask_overlaps[j, i] = True  \n",
    "\n",
    "    for num_masks_to_choose in range(num_masks_to_return, 0, -1):\n",
    "        min_total_distance = float('inf')\n",
    "        best_indices = None\n",
    "\n",
    "        max_combinations = 100000  \n",
    "        combination_count = 0\n",
    "\n",
    "        for combo in combinations(range(total_masks), num_masks_to_choose):\n",
    "            combination_count += 1\n",
    "            if combination_count > max_combinations:\n",
    "                break  \n",
    "\n",
    "            has_overlap = False\n",
    "            for i, j in combinations(combo, 2):\n",
    "                if mask_overlaps[i, j]:\n",
    "                    has_overlap = True\n",
    "                    break\n",
    "            if has_overlap:\n",
    "                continue \n",
    "\n",
    "            total_distance = 0\n",
    "            for i, j in combinations(combo, 2):\n",
    "                total_distance += pairwise_distances[i, j]\n",
    "            if total_distance < min_total_distance:\n",
    "                min_total_distance = total_distance\n",
    "                best_indices = combo\n",
    "\n",
    "        if best_indices is not None:\n",
    "            selected_masks = [masks[i] for i in best_indices]\n",
    "            break \n",
    "\n",
    "    if best_indices is None:\n",
    "        image_center = np.array([shape[1] / 2, shape[0] / 2])\n",
    "        distances_to_center = np.linalg.norm(centroids_array - image_center, axis=1)\n",
    "        closest_index = np.argmin(distances_to_center)\n",
    "        selected_masks = [masks[closest_index]]\n",
    "    \n",
    "    num_masks_missing = num_masks_to_return - len(selected_masks)\n",
    "    if num_masks_missing > 0:\n",
    "        empty_mask = np.zeros(shape, dtype=np.uint8)\n",
    "        selected_masks.extend([empty_mask for _ in range(num_masks_missing)])\n",
    "\n",
    "    selected_masks_uint8 = [(mask * 255).astype(np.uint8) for mask in selected_masks]\n",
    "    return selected_masks_uint8\n",
    "\n",
    "def fill_gaps_between_masks(masks, distance_threshold):\n",
    "    num_masks = len(masks)\n",
    "    h, w = masks[0].shape\n",
    "\n",
    "    labeled_image = np.zeros((h, w), dtype=np.int32)\n",
    "    for idx, mask in enumerate(masks, start=1):\n",
    "        labeled_image[mask > 0] = idx\n",
    "\n",
    "    unfilled_merged_mask = (labeled_image > 0).astype(np.uint8) * 255\n",
    "\n",
    "    distance_maps = np.zeros((num_masks, h, w), dtype=np.float32)\n",
    "    for idx in range(num_masks):\n",
    "        mask = masks[idx]\n",
    "        cv2.imwrite(f'./results/multimask/mask_{idx}.jpg', cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\n",
    "        distance_maps[idx] = ndimage.distance_transform_edt(mask == 0)\n",
    "\n",
    "    within_threshold = distance_maps <= distance_threshold\n",
    "    sum_within_threshold = np.sum(within_threshold, axis=0)\n",
    "    between_masks = sum_within_threshold > 1\n",
    "\n",
    "    min_distances = np.min(distance_maps[:, between_masks], axis=0)\n",
    "    min_indices = np.argmin(distance_maps[:, between_masks], axis=0)\n",
    "\n",
    "    expanded_labels = labeled_image.copy()\n",
    "    idxs = np.where(between_masks)\n",
    "    expanded_labels[idxs] = min_indices + 1\n",
    "\n",
    "    updated_masks = []\n",
    "    for idx in range(1, num_masks + 1):\n",
    "        updated_mask = (expanded_labels == idx).astype(np.uint8)\n",
    "        updated_masks.append(updated_mask)\n",
    "\n",
    "    updated_masks_uint8 = [(mask * 255).astype(np.uint8) for mask in updated_masks]\n",
    "\n",
    "    filled_merged_mask = (expanded_labels > 0).astype(np.uint8) * 255\n",
    "\n",
    "    return unfilled_merged_mask, filled_merged_mask, updated_masks_uint8\n",
    "\n",
    "\n",
    "style_image_files = [f'./results/styles/style-{i}.jpg' for i in range(13)]\n",
    "\n",
    "feature_combinations = [\n",
    "    #{\"cookie_cutter\": True, \"penetrate_initial_mask_pixels\": 0, \"feathering\": False},   #1 o,x,x\n",
    "    #{\"cookie_cutter\": False, \"penetrate_initial_mask_pixels\": 7, \"feathering\": False},  #2 x,o,x\n",
    "    #{\"cookie_cutter\": False, \"penetrate_initial_mask_pixels\": 0, \"feathering\": True},   #3 x,x,o\n",
    "    #{\"cookie_cutter\": True, \"penetrate_initial_mask_pixels\": 7, \"feathering\": False},   #4 o,o,x\n",
    "    #{\"cookie_cutter\": True, \"penetrate_initial_mask_pixels\": 0, \"feathering\": True},    #5 o,x,o\n",
    "    #{\"cookie_cutter\": False, \"penetrate_initial_mask_pixels\": 7, \"feathering\": True},   #6 x,o,o\n",
    "    {\"cookie_cutter\": True, \"penetrate_initial_mask_pixels\": 7, \"feathering\": True},    #7 o,o,o\n",
    "    #{\"cookie_cutter\": False, \"penetrate_initial_mask_pixels\": 0, \"feathering\": False}   #8 x,x,x\n",
    "]\n",
    "\n",
    "for img_index in range(137, 138):\n",
    "    file = f\"sa_{img_index}.jpg\"\n",
    "    filename = file.replace('.jpg', '')\n",
    "    img_path = os.path.join(data_dir, file)\n",
    "    json_path = img_path.replace('.jpg', '.json')\n",
    "    \n",
    "    image_to_be_processed = cv2.imread(img_path)\n",
    "    if image_to_be_processed is None:\n",
    "        print(f\"Image {file} not found. Skipping.\")\n",
    "        continue\n",
    "    with open(json_path, 'r') as json_file:\n",
    "        masks = []\n",
    "        style_image_filenames = []\n",
    "        \n",
    "        data = json.load(json_file)\n",
    "        width = data[\"image\"][\"width\"]\n",
    "        height = data[\"image\"][\"height\"]\n",
    "        image_area = width * height\n",
    "        min_area = image_area * 0.03\n",
    "        \n",
    "        masks_count = 2\n",
    "        #masks = extract_closest_masks(data, (height, width), min_area, masks_count)\n",
    "        grayscale = cv2.cvtColor(cv2.imread('mask_1.jpg'), cv2.COLOR_BGR2GRAY)\n",
    "        _, binary_mask = cv2.threshold(grayscale, 127, 255, cv2.THRESH_BINARY)\n",
    "        masks.append(binary_mask)\n",
    "        grayscale = cv2.cvtColor(cv2.imread('mask_2.jpg'), cv2.COLOR_BGR2GRAY)\n",
    "        _, binary_mask = cv2.threshold(grayscale, 127, 255, cv2.THRESH_BINARY)\n",
    "        masks.append(binary_mask)\n",
    "        \n",
    "        style_image_filenames = random.sample(style_image_files, masks_count)\n",
    "        style_image_filenames = ['./results/styles/style-3.jpg', './results/styles/style-0.jpg']\n",
    "        \n",
    "        # Apply each feature combination\n",
    "        for i, features in enumerate(feature_combinations, 1):\n",
    "            \n",
    "            processed_image, merged_mask_tensor = partial_convolution(\n",
    "                image_to_be_processed, \n",
    "                masks, \n",
    "                style_image_filenames, \n",
    "                feathering=features[\"feathering\"], \n",
    "                penetrate_initial_mask_pixels=features[\"penetrate_initial_mask_pixels\"],\n",
    "                cookie_cutter=features[\"cookie_cutter\"],\n",
    "                index=i,\n",
    "                resize_style_image=False\n",
    "            )\n",
    "            cv2.imwrite(f'./results/multimask/{filename}_feature_{i}.jpg', cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))\n",
    "            #cv2.imwrite(f\"./results/multimask/{filename}_unfilled_merged_mask_{i}.png\", unfilled_mask)\n",
    "            #cv2.imwrite(f\"./results/multimask/{filename}_filled_merged_mask_{i}.png\", filled_mask)\n",
    "            print(f'{filename}_feature_{i}.jpg was written. style_images were {style_image_filenames}')       \n",
    "           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
